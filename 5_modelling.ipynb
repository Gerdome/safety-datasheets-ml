{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrian/coding/rtbda_seminar/rtbda_venv/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "from sklearn.svm import LinearSVC #SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# Other Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.externals import joblib\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mappings\n",
    "label_group_dict = { 0: 0,\n",
    "                     1: 'chapter',\n",
    "                     2: 'company',\n",
    "                     3: 'directive',\n",
    "                     4: 'signal',\n",
    "                     5: 'subchapter',\n",
    "                     6: 'usecase_con',\n",
    "                     7: 'usecase_pro',\n",
    "                     8: 'version'}\n",
    "\n",
    "date_dict = {0: 0,\n",
    "             1: 'oldversiondate',\n",
    "             2: 'validdate',\n",
    "             3: 'printdate',\n",
    "             4: 'revisiondate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_feature_rng (data):\n",
    "    # Ranges Feature\n",
    "    colidx = data.columns.get_loc\n",
    "    # No window\n",
    "    r_paper = np.r_[colidx('word.is.lower'):colidx('word.is.stop')]\n",
    "    r_own = np.r_[colidx('word.is.bold'):colidx('is.page.3')]\n",
    "    r_own_date_spe = np.r_[colidx('word.is.print.date.trigger'):colidx('word.is.oldversion.date.trigger')]\n",
    "    r_own_date_full = np.r_[r_own, r_own_date_spe]\n",
    "    r_web = np.r_[colidx('0'):colidx('299')]\n",
    "\n",
    "    feature_selection = [('Paper', r_paper),\n",
    "                        ('Own', r_own),\n",
    "                        ('Wordembedding', r_web),\n",
    "                        ('Own+Paper', np.r_[r_own, r_paper]),\n",
    "                        ('Own+Wordembedding', np.r_[r_own, r_web]),\n",
    "                        ('Paper+Wordembedding', np.r_[r_paper, r_web]),\n",
    "                        ('Own+Paper+Wordembedding', np.r_[r_own, r_paper, r_web]),\n",
    "                        ('date_Paper', r_paper),\n",
    "                        ('date_Own_std', r_own),\n",
    "                        ('date_Own_spe', r_own_date_spe),\n",
    "                        ('date_Own_full', r_own_date_full),\n",
    "                        ('date_Own_full+Paper', np.r_[r_own_date_full, r_paper]),\n",
    "                        ('date_Own_full+Wordembedding', np.r_[r_own_date_full, r_web]),\n",
    "                        ('date_Paper+Wordembedding', np.r_[r_paper, r_web]),\n",
    "                        ('date_Own_full+Paper+Wordembedding', np.r_[r_own_date_full, r_paper, r_web]),\n",
    "                        ]\n",
    "\n",
    "    return feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_feature_rng_w (data):\n",
    "    # Ranges Feature\n",
    "    colidx = data.columns.get_loc\n",
    "\n",
    "    # With window\n",
    "    r_paper_w = np.r_[colidx('word.is.lower'):colidx('+6_word.is.stop')]\n",
    "    r_own_w = np.r_[colidx('word.is.bold'):colidx('+6_is.page.3')]\n",
    "    r_own_date_spe_w = np.r_[colidx('word.is.print.date.trigger'):colidx('+6_word.is.oldversion.date.trigger')]\n",
    "    r_own_date_full_w = np.r_[r_own_w, r_own_date_spe_w]\n",
    "    r_web_w = np.r_[colidx('0'):colidx('+1_299')]\n",
    "\n",
    "    feature_selection_w = [('Paper', r_paper_w),\n",
    "                        ('Own', r_own_w),\n",
    "                        ('Wordembedding', r_web_w),\n",
    "                        ('Own+Paper', np.r_[r_own_w, r_paper_w]),\n",
    "                        ('Own+Wordembedding', np.r_[r_own_w, r_web_w]),\n",
    "                        ('Paper+Wordembedding', np.r_[r_paper_w, r_web_w]),\n",
    "                        ('Own+Paper+Wordembedding', np.r_[r_own_w, r_paper_w, r_web_w]),\n",
    "                        ('date_Paper', r_paper_w),\n",
    "                        ('date_Own_std', r_own_w),\n",
    "                        ('date_Own_spe', r_own_date_spe_w),\n",
    "                        ('date_Own_full', r_own_date_full_w),\n",
    "                        ('date_Own_full+Paper', np.r_[r_own_date_full_w, r_paper_w]),\n",
    "                        ('date_Own_full+Wordembedding', np.r_[r_own_date_full_w, r_web_w]),\n",
    "                        ('date_Paper+Wordembedding', np.r_[r_paper_w, r_web_w]),\n",
    "                        ('date_Own_full+Paper+Wordembedding', np.r_[r_own_date_full_w, r_paper_w, r_web_w]),\n",
    "                        ]\n",
    "    \n",
    "    return feature_selection_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data (data, sample_size): #max sample_size = 527\n",
    "    # Create Dataframe of unique docs to use sample function from pandas with random state\n",
    "    docs = pd.DataFrame(data.doc.unique())\n",
    "    random_docs = docs[0].sample(n=sample_size, random_state=1).values.tolist()\n",
    "    data_sample = data[data['doc'].isin(random_docs)]\n",
    "    data_sample1 = data_sample.loc[:, 'doc':'chem']\n",
    "    data_sample2 = data_sample.loc[:, 'word.is.lower':data.iloc[:,-1].name]\n",
    "\n",
    "    # Replace missing values\n",
    "    data_sample2 = data_sample2.fillna(data_sample2.mode().iloc[0])\n",
    "    data_sample = pd.concat([data_sample1, data_sample2], axis=1, sort=False)\n",
    "\n",
    "    # Split random_docs in test and training sets\n",
    "    docs_train, docs_test = train_test_split(random_docs, random_state=1)\n",
    "\n",
    "    # Split random_data in test and training sets\n",
    "    train, test = data_sample[data_sample['doc'].isin(docs_train)], data_sample[data_sample['doc'].isin(docs_test)]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (wid,feat,lab):\n",
    "    print ('   **************************Label:' + lab + '**************************')\n",
    "    # Separate random_data training/test split in features and labels\n",
    "    x_train = train.iloc[:, feat[1]]\n",
    "    x_test = test.iloc[:, feat[1]]\n",
    "    y_train = train.loc[:, lab]\n",
    "    y_test = test.loc[:, lab]\n",
    "\n",
    "    # training\n",
    "    start = timer()\n",
    "    clf = RandomForestClassifier(n_estimators=25)\n",
    "    clf.fit (x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    end = timer()\n",
    "    print('Seconds for training:', end - start)\n",
    "\n",
    "    # scores\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "\n",
    "    # Output a pickle file for the model\n",
    "    joblib.dump(clf, './models/'+ wid + feat[0] + '_' + lab + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_training (wid, feature_selection, lab):\n",
    "    for feat in feature_selection:\n",
    "        print ('*******************************Features:' + feat[0] + '*******************************')\n",
    "    \n",
    "        if feat[0].startswith('date'):\n",
    "            train_model(wid, feat,'date')\n",
    "        else:\n",
    "            for l in lab:\n",
    "                train_model(wid, feat, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('***************************************NO_WINDOW***************************************')\n",
    "data = pd.read_pickle('data_model_allfeatw13_web.pkl')\n",
    "feature_selection = set_feature_rng(data)\n",
    "train, test = prepare_data(data, 527)\n",
    "start_training('', feature_selection, ['label_group', 'chem', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('***************************************WINDOW***************************************')\n",
    "data = pd.read_pickle('data_model_allfeatw13_web3.pkl')\n",
    "feature_selection_w = set_feature_rng_w(data)\n",
    "train, test = prepare_data(data, 527)\n",
    "start_training('window_', feature_selection_w, ['label_group', 'chem', 'date'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtbda_venv",
   "language": "python",
   "name": "rtbda_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
